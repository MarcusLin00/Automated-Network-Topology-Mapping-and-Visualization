# monitors/malware_phishing_monitor.py
import asyncio
import logging
import time
import requests
import json
from config import THREAT_INTEL_API_URL, THREAT_INTEL_TIMEOUT, THREAT_INTEL_RETRIES
from scapy.all import conf, sniff, DNS, DNSQR, IP, TCP, AsyncSniffer
from urllib.parse import urlparse
from datetime import datetime
from typing import Callable
from .base_monitor import BaseMonitor

class MalwarePhishingMonitor(BaseMonitor):
    """Class to detect malware and phishing attempts by monitoring DNS and HTTP traffic."""

    def __init__(
        self,
        alert_callback: Callable[[str, str, str], asyncio.Future],
        loop: asyncio.AbstractEventLoop,
        cooldown: int = 300
    ):
        """
        Initializes the MalwarePhishingMonitor.

        :param alert_callback: Async callback function to send alerts.
        :param loop: The asyncio event loop to schedule coroutines.
        :param cooldown: Time period to wait before sending another alert for the same IP/domain.
        """
        self.alert_callback = alert_callback
        self.cooldown = cooldown
        self.alerted_hosts = {}  # {host: last_alert_timestamp}
        self.loop = loop
        self.sniffer = None 

    def query_urlhaus(self, url):
                """Check URL with URLHaus API to see if it is a known malicious domain."""
                # Remove any trailing period from the domain name
                url = url.rstrip('.')
                # url = url + '/' 
                
                # Ensure the URL includes a scheme (http:// or https://)
                if not urlparse(url).scheme:
                    url = f"http://{url}"  # Add "http://" if no scheme is provided

                urlhaus_api_url = f"{THREAT_INTEL_API_URL}"
                data = {'url': url}  # URL to query
                for attempt in range(THREAT_INTEL_RETRIES):
                    try:
                        # Send POST request with URL as a parameter
                        response = requests.post(urlhaus_api_url, data=data, timeout=THREAT_INTEL_TIMEOUT)
                       
                        # Check if response was successful (status code 200)
                        if response.status_code == 200:
                            try:
                                json_response = response.json()
                                # logging.debug(f"URLHaus API response: {json.dumps(json_response, indent=2)}")

                                # Check the query status in the response
                                if json_response.get('query_status') == 'ok':
                                    logging.info(f"{url} found in URLHaus threat intelligence.")
                                    return True
                                elif json_response.get('query_status') == 'no_results':
                                    logging.info(f"{url} not found in URLHaus database.")
                                    return False
                                else:
                                    logging.error(f"Unexpected query status: {json_response.get('query_status')}")
                                    return False
                            except json.JSONDecodeError as e:
                                logging.error(f"Failed to parse JSON response: {e}")
                                return False
                        else:
                            logging.error(f"Received non-200 response: {response.status_code}")
                            return False
                    except requests.RequestException as e:
                        logging.warning(f"Attempt {attempt + 1} failed: {e}")
                
                logging.error("All attempts to reach URLHaus API failed.")
                return False


    def detect(self, packet):
        current_time = time.time()

        # Check for DNS queries
        if packet.haslayer(DNS) and packet.getlayer(DNS).qr == 0:
            query_name = packet[DNSQR].qname.decode('utf-8')
            src_ip = packet[IP].src
            host_ip = packet[IP].dst

            logging.debug(f"DNS Query Detected: {query_name} from {src_ip}")

            # Check if queried domain is flagged as malicious
            if self.query_urlhaus(query_name):
                last_alert_time = self.alerted_hosts.get(query_name, 0)
                if current_time - last_alert_time >= self.cooldown:
                    event_name = "Malware/Phishing Domain Access Detected"
                    alert_message = f"Suspicious domain access detected from IP {src_ip}: {query_name} at {datetime.now().isoformat()}"
                    logging.warning(alert_message)
                    # Schedule the alert coroutine on the provided event loop
                    asyncio.run_coroutine_threadsafe(
                        self.alert_callback(event_name, alert_message, self._generate_event_id(host_ip)),
                        self.loop
                    )
                    # Update the last alert time
                    self.alerted_hosts[query_name] = current_time
                else:
                    logging.debug(f"Cooldown active for {query_name}. Alert not sent.")


    def _generate_event_id(self, host_ip):
        """Generate a unique identifier for a suspicious domain access event."""
        return f"malware_phishing_{host_ip}_{int(time.time())}"

    # def _generate_event_id(self, src_ip, query_name):
    #     """Generate a unique identifier for a suspicious domain access event."""
    #     return f"malware_phishing_{src_ip}_{query_name}_{int(time.time())}"

    def start(self):
        logging.info("Starting MalwarePhishingMonitor...")
        self.sniffer = AsyncSniffer(filter="udp port 53", prn=self.detect, store=0)
        self.sniffer.start()

    def stop(self):
        if self.sniffer:
            logging.info("Stopping MalwarePhishingMonitor...")
            self.sniffer.stop()
            self.sniffer = None